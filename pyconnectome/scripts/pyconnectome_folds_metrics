#! /usr/bin/env python3
# -*- coding: utf-8 -*
##########################################################################
# NSAp - Copyright (C) CEA, 2018
# Distributed under the terms of the CeCILL-B license, as published by
# the CEA-CNRS-INRIA. Refer to the LICENSE file or to
# http://www.cecill.info/licences/Licence_CeCILL-B_V1-en.html for details.
##########################################################################

# System import
import os
import json
import argparse
import textwrap
import collections
from argparse import RawTextHelpFormatter
from datetime import datetime
from pprint import pprint

# Bredala module
try:
    import bredala
    bredala.USE_PROFILER = False
    bredala.register("pyconnectome.utils.filetools",
                     names=["parse_graph"])
    bredala.register("pyconnectome.metrics.dfold",
                     names=["convert_fold", "convert_mesh",
                            "sphere_integration"])
except:
    pass

# Package import
from pyconnectome import __version__ as version
from pyconnectome.utils.filetools import parse_graph
from pyconnectome.metrics.dfold import convert_folds
from pyconnectome.metrics.dfold import convert_mesh
from pyconnectome.metrics.dfold import sphere_integration
from pyconnectome.metrics.dfold import SPHERE_INTEGRATION_METRICS

# Third party import
import numpy as np


# Parameters to keep trace
__hopla__ = ["runtime", "inputs", "outputs"]


# Script documentation
DOC = """
Evaluation of folds metrics
---------------------------

Extract features (e.g : FA) along different folds and output a summary of
these features in csv and json files (default). This script works also for PIT
or parcellation input features if the appropiate options are set (-P or -I with
-G options).

Default requirements:
    - fold files (.gii) for left and right hemisphere (required).
    - T1 image file (required).
    - scalar image files (e.g FA image file) (required).
    - subject id (required).
    - morphologist graph files (.arg) for left and right hemisphere (required).
    - folds' ids on which to extract features for each hemisphere:
      if no fold is specified features are extracted on every folds,
      if -1 is specified no fold is extracted (optional).
    - white/grey matter segmentation files for left and right hemisphere
      (optional).

Command example for fold features' computation on HCP data:

For fold features' computation
python $HOME/git/pyconnectome/pyconnectome/scripts/pyconnectome_folds_metrics \
    -o /tmp/HCP_FOLDS \
    -s 101006 \
    -t /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/101006.nii.gz \
    -a $PROJECT/HCP_FOLDS/TEST_OUTPUT/101006/3000/dtifit_FA.nii.gz \
    -F /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/folds/3.1/default_session_auto/L101006_default_session_auto.data/aims_Tmtktri.gii \
       /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/folds/3.1/default_session_auto/R101006_default_session_auto.data/aims_Tmtktri.gii \
    -A /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/folds/3.1/default_session_auto/L101006_default_session_auto.arg \
       /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/folds/3.1/default_session_auto/R101006_default_session_auto.arg \
    -M /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/segmentation/Lgrey_white_101006.nii.gz \
       /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/segmentation/Rgrey_white_101006.nii.gz \
    -L 86 \
    -R 86 \
    -D 2

Command example for PIT features' computation on HCP data:

python $HOME/git/pyconnectome/pyconnectome/scripts/pyconnectome_folds_metrics \
    -o /tmp/HCP_PITS \
    -s 101006 \
    -t /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/101006.nii.gz \
    -a /neurospin/hcp/ANALYSIS/3T_diffusion_scalars/101006/dtifit_FA.nii.gz \
       /neurospin/hcp/ANALYSIS/3T_diffusion_scalars/101006/dtifit_MD.nii.gz \
       /neurospin/hcp/ANALYSIS/3T_diffusion_scalars/101006/qball_gfa.nii.gz \
    -M /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/segmentation/Lgrey_white_101006.nii.gz \
       /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/default_analysis/segmentation/Rgrey_white_101006.nii.gz \
    -I /neurospin/hcp/ANALYSIS/3T_pits/101006/t1mri/BL/default_analysis/segmentation/mesh/surface_analysis/101006_Lwhite_pits_corrected.gii \
       /neurospin/hcp/ANALYSIS/3T_pits/101006/t1mri/BL/default_analysis/segmentation/mesh/surface_analysis/101006_Rwhite_pits_corrected.gii \
    -G /neurospin/hcp/ANALYSIS/3T_pits/101006/t1mri/BL/default_analysis/segmentation/mesh/101006_Lwhite.gii \
       /neurospin/hcp/ANALYSIS/3T_pits/101006/t1mri/BL/default_analysis/segmentation/mesh/101006_Rwhite.gii \
    -Z /neurospin/hcp/ANALYSIS/3T_freesurfer/101006/T1w/101006/mri/aseg.mgz \
    -N /neurospin/hcp/ANALYSIS/3T_freesurfer_extras/101006/convert/images/rawavg.native.nii.gz \
    -D 2

Command example for parcallation features' computation on HCP data:

python $HOME/git/pyconnectome/pyconnectome/scripts/pyconnectome_folds_metrics \
     -o /tmp/HCP_PARCELS \
     -s 101006 \
     -t /neurospin/hcp/ANALYSIS/3T_morphologist/101006/t1mri/default_acquisition/101006.nii.gz \
     -a /neurospin/hcp/ANALYSIS/3T_diffusion_scalars/101006/dtifit_FA.nii.gz \
        /neurospin/hcp/ANALYSIS/3T_diffusion_scalars/101006/dtifit_MD.nii.gz \
        /neurospin/hcp/ANALYSIS/3T_diffusion_scalars/101006/qball_gfa.nii.gz \
     -P /neurospin/hcp/ANALYSIS/3T_freesurfer/101006/T1w/101006/label/lh.aparc.annot \
        /neurospin/hcp/ANALYSIS/3T_freesurfer/101006/T1w/101006/label/rh.aparc.annot \
     -G /neurospin/hcp/ANALYSIS/3T_pits/101006/t1mri/BL/default_analysis/segmentation/mesh/101006_Lwhite.gii \
        /neurospin/hcp/ANALYSIS/3T_pits/101006/t1mri/BL/default_analysis/segmentation/mesh/101006_Rwhite.gii \
     -Z /neurospin/hcp/ANALYSIS/3T_freesurfer/101006/T1w/101006/mri/aseg.mgz \
     -N /neurospin/hcp/ANALYSIS/3T_freesurfer_extras/101006/convert/images/rawavg.native.nii.gz
"""


def is_file(filepath):
    """ Check file's existence - argparse 'type' argument.
    """
    if not os.path.isfile(filepath):
        raise argparse.ArgumentError("File does not exist: %s" % filepath)
    return filepath


def is_directory(dirarg):
    """ Type for argparse - checks that directory exists.
    """
    if not os.path.isdir(dirarg):
        raise argparse.ArgumentError(
            "The directory '{0}' does not exist!".format(dirarg))
    return dirarg


# Parse input arguments
def get_cmd_line_args():
    """
    Create a command line argument parser and return a dict mapping
    <argument name> -> <argument value>.
    """
    parser = argparse.ArgumentParser(
        prog="python pyconnectome_get_folds_metrics",
        description=textwrap.dedent(DOC),
        formatter_class=RawTextHelpFormatter)

    # Required arguments
    required = parser.add_argument_group("required arguments")
    required.add_argument(
        "-o", "--outdir",
        type=is_directory, required=True, metavar="<path>",
        help="Directory where to output.")
    required.add_argument(
        "-s", "--subject", type=str, required=True, help="Subject ID.")
    required.add_argument(
        "-t", "--t1",
        type=is_file, required=True, metavar="<path>",
        help="Path to the T1 image file.")
    required.add_argument(
        "-a", "--scalarfile",
        type=is_file, nargs='+', required=True, metavar="<path>",
        help="Path to at least one scalar image file.")

    # Optional argument
    parser.add_argument(
        "-F", "--foldsfile",
        type=is_file, nargs='+', metavar="<path>",
        help="Path to the folds .gii file. The left hemisphere folds file must"
             "be the first input")
    required.add_argument(
        "-A", "--graphfile",
        type=is_file, nargs='+', metavar="<path>",
        help="Path to the morphologist graph file. The left hemisphere graph "
             "file must be the first input")
    parser.add_argument(
        "-L", "--leftfolds",
        type=int, nargs='*',
        help="Selection of left hemisphere folds indexes on which to compute"
             "value (e.g : 94). Not adding this argument will compute the"
             "folds' metrics on every fold and putting this argument to -1"
             "won't compute any value for the hemisphere folds.")
    parser.add_argument(
        "-R", "--rightfolds",
        type=int, nargs='*',
        help="Selection of right hemisphere folds indexes on which to compute"
             "value (e.g : 94). Not adding this argument will compute the"
             "folds' metrics on every fold and putting this argument to -1"
             "won't compute any value for the hemisphere folds.")
    parser.add_argument(
        "-P", "--parcellationfiles",
        type=is_file, nargs='*',
        help="Selection of left and right hemisphere parcellation labels on"
             "which to compute scalar values. Not adding this argument will "
             "compute thescalars' metrics on folds instead of pits. The "
             "left hemisphere pits indexes must be the first input.")
    parser.add_argument(
        "-I", "--pitsfiles",
        type=is_file, nargs='*',
        help="Selection of left and right hemisphere pits indexes on which to"
             "compute scalar values. Not adding this argument will compute the"
             "scalars' metrics on folds instead of pits. The left hemisphere"
             "pits indexes must be the first input.")
    parser.add_argument(
        "-G", "--meshfiles",
        type=is_file, nargs='*',
        help="Selection of left and right hemisphere white mesh file. The left"
             "hemisphere white mesh file must be the first input.")
    parser.add_argument(
        "-M", "--wgmfile",
        type=is_file, nargs='*', metavar="<path>",
        help="Path to the white/grey matter segmentation files. The left "
              "hemisphere segmentation file must be the first input")
    parser.add_argument(
        "-Z", "--mgzfile",
        type=is_file, metavar="<path>",
        help="Path to a FreeSurfer '.mgz' file.")
    parser.add_argument(
        "-N", "--fsnative", type=is_file, metavar="<path>",
        help="Path to a Freesurfer mesh. If set, consider the input mesh as a "
             "FreeSurfer mesh in the conformed space, otherwise a "
             "morphologist mesh")
    parser.add_argument(
        "-D", "--radius", type=float,
        help="The sphere integration radius. If None no integration is "
             "performed.")
    parser.add_argument(
        "-C", "--use-conformed-translation", action="store_false",
        help="If set apply the translation to go from the conformed to "
             "native space.")
    parser.add_argument(
        "-V", "--verbose",
        type=int, choices=[0, 1, 2], default=2,
        help="Increase the verbosity level: 0 silent, [1, 2] verbose.")

    # Create a dict of arguments to pass to the 'main' function
    args = parser.parse_args()
    kwargs = vars(args)
    verbose = kwargs.pop("verbose")
    return kwargs, verbose

"""
Parse the command line.
"""
inputs, verbose = get_cmd_line_args()
runtime = {
    "tool": "pyconnectome_get_folds_metrics",
    "tool_version": version,
    "timestamp": datetime.now().isoformat()}
outputs = None
sid_outdir = os.path.join(inputs["outdir"], inputs["subject"])
if not os.path.isdir(sid_outdir):
    os.mkdir(sid_outdir)
if verbose > 0:
    pprint("[info] Starting computation of folds metrics...")
    pprint("[info] Runtime:")
    pprint(runtime)
    pprint("[info] Inputs:")
    pprint(inputs)

"""
Start the labels/folds/pits' metrics computation.
"""
# Compute scalar values on pits instead of folds
# Extract pits coordinates from white/grey matter mesh in physical
# morphological space and put them in NIFTI voxel space.
if inputs["pitsfiles"] is not None:
    average = False
    mesh_l, indexes_pits_l, _ = convert_mesh(
        texture_file=inputs["pitsfiles"][0],
        mesh_file=inputs["meshfiles"][0],
        t1_file=inputs["t1"],
        outpattern=os.path.join(sid_outdir,
                                "lh.{0}.".format(inputs["subject"])),
        mgz_file=inputs["mgzfile"],
        freesurfer_conformed=inputs["use_conformed_translation"],
        freesurfer_native_t1_file=inputs["fsnative"])
    mesh_pits_l = mesh_l[indexes_pits_l[0]]
    mesh_r, indexes_pits_r, _ = convert_mesh(
        texture_file=inputs["pitsfiles"][1],
        mesh_file=inputs["meshfiles"][1],
        t1_file=inputs["t1"],
        outpattern=os.path.join(sid_outdir,
                                "rh.{0}.".format(inputs["subject"])),
        mgz_file=inputs["mgzfile"],
        freesurfer_conformed=inputs["use_conformed_translation"],
        freesurfer_native_t1_file=inputs["fsnative"])
    mesh_pits_r = mesh_r[indexes_pits_r[0]]
    points_l = collections.OrderedDict()
    for pos in range(len(mesh_pits_l.shape[0])):
        points_l[indexes_pits_l[0][pos]] = mesh_pits_l[pos].reshape(1, 3)
    points_r = collections.OrderedDict()
    for pos in range(len(mesh_pits_r.shape[0])):
        points_r[indexes_pits_r[0][pos]] = mesh_pits_r[pos].reshape(1, 3)

# Compute scalar values on paracellations instead of folds
# Extract coordinates from white/grey matter mesh in physical
# morphological space and put them in NIFTI voxel space.
if inputs["parcellationfiles"] is not None:
    average = True
    mesh_l, indexes_labels_l, names_labels_l = convert_mesh(
        texture_file=inputs["parcellationfiles"][0],
        mesh_file=inputs["meshfiles"][0],
        t1_file=inputs["t1"],
        outpattern=os.path.join(sid_outdir,
                                "lh.{0}.".format(inputs["subject"])),
        mgz_file=inputs["mgzfile"],
        freesurfer_conformed=inputs["use_conformed_translation"],
        freesurfer_native_t1_file=inputs["fsnative"])
    mesh_r, indexes_labels_r, names_labels_r = convert_mesh(
        texture_file=inputs["parcellationfiles"][1],
        mesh_file=inputs["meshfiles"][1],
        t1_file=inputs["t1"],
        outpattern=os.path.join(sid_outdir,
                                "rh.{0}.".format(inputs["subject"])),
        mgz_file=inputs["mgzfile"],
        freesurfer_conformed=inputs["use_conformed_translation"],
        freesurfer_native_t1_file=inputs["fsnative"])
    points_l = collections.OrderedDict()
    for name, indices in zip(names_labels_l, indexes_labels_l):
        points_l[name] = mesh_l[indices]
    points_r = collections.OrderedDict()
    for name, indices in zip(names_labels_r, indexes_labels_r):
        points_r[name] = mesh_r[indices]

# Compute scalar values on folds
else:
    average = False
    # Parse the Morphologist graph file to get the fold labels
    labels_l = parse_graph(inputs["graphfile"][0])
    labels_r = parse_graph(inputs["graphfile"][1])

    # Convert the folds in physical morphological space to NIFTI voxel space
    folds_l = convert_folds(inputs["foldsfile"][0], inputs["graphfile"][0],
                            inputs["t1"])
    folds_r = convert_folds(inputs["foldsfile"][1], inputs["graphfile"][1],
                            inputs["t1"])
    points_l = collections.OrderedDict()
    points_r = collections.OrderedDict()

    # If no folds were specified, select all folds vertices for the computation
    if inputs["leftfolds"] is None:
        for ind in labels_l.keys():
            points_l[ind] = folds_l[ind].vertices
    # If the user specified folds (-1 == no folds), do the computation on these
    # folds vertices
    elif inputs["leftfolds"][0] != -1:
        for ind in inputs["leftfolds"]:
            points_l[ind] = folds_l[ind].vertices

    if inputs["rightfolds"] is None:
        for ind in labelsR.keys():
            points_r[ind] = folds_r[ind].vertices
    elif inputs["rightfolds"][0] != -1:
        for ind in inputs["rightfolds"]:
            points_r[ind] = folds_r[ind].vertices


# Extract scalar values on folds/pits/paracellations
if inputs["wgmfile"] is None:
    wgm_l, wgm_r = (None, None)
else:
    wgm_l = inputs["wgmfile"][0]
    wgm_r = inputs["wgmfile"][1]
measures_l, scalar_names_l = sphere_integration(
    t1_file=inputs["t1"],
    scalars=inputs["scalarfile"],
    points=points_l,
    seg_file=wgm_l,
    radius=inputs["radius"],
    average=average,
    outpattern=os.path.join(sid_outdir, "lh.{0}.".format(inputs["subject"])))
measures_r, scalar_names_r = sphere_integration(
    t1_file=inputs["t1"],
    scalars=inputs["scalarfile"],
    points=points_r,
    seg_file=wgm_r,
    radius=inputs["radius"],
    average=average,
    outpattern=os.path.join(sid_outdir, "rh.{0}.".format(inputs["subject"])))
assert scalar_names_l == scalar_names_r

# Write csv and json output
if inputs["pitsfiles"] is not None:
    out_file_l = os.path.join(
        sid_outdir, "lh_{0}_pits_measure".format(inputs["subject"]))
    out_file_r = os.path.join(
        sid_outdir, "rh_{0}_pits_measure".format(inputs["subject"]))
elif inputs["parcellationfiles"] is not None:
    out_file_l = os.path.join(
        sid_outdir, "lh_{0}_parcels_measure".format(inputs["subject"]))
    out_file_r = os.path.join(
        sid_outdir, "rh_{0}_parcels_measure".format(inputs["subject"]))
else:
    out_file_l = os.path.join(
        sid_outdir, "lh_{0}_folds_measure".format(inputs["subject"]))
    out_file_r = os.path.join(
        sid_outdir, "rh_{0}_folds_measure".format(inputs["subject"]))
out_files = {out_file_l: measures_l, out_file_r: measures_r}
for out_file, measures in out_files.items():
    with open("{0}.json".format(out_file), "wt") as f:
        json.dump(measures, f, indent=4)
    with open("{0}.csv".format(out_file), "wt") as f:
        header = "Index;VertexCoordinates"
        for name in scalar_names_r:
            for metric in SPHERE_INTEGRATION_METRICS:
                header += ";{0}-{1}".format(name, metric)
        f.write(header)
        f.write("\n")
        for label in measures.keys():
            for point, point_struct in measures[label].items():
                line = "{0};{1}".format(label, point)
                for name in scalar_names_r:
                    for metric in SPHERE_INTEGRATION_METRICS:
                        line += ";{0}".format(point_struct[name][metric])
                f.write(line)
                f.write("\n")

"""
Update the outputs and save them and the inputs in a 'logs' directory.
"""

outputs = {
    "measures_left_hemi": [
        "{0}.{1}".format(out_file_l, "csv"),
        "{0}.{1}".format(out_file_l, "json")],
    "measures_right_hemi": [
        "{0}.{1}".format(out_file_r, "csv"),
        "{0}.{1}".format(out_file_r, "json")]
}
logdir = os.path.join(sid_outdir, "logs")
if not os.path.isdir(logdir):
    os.mkdir(logdir)
params = locals()
for name, final_struct in [("inputs_{0}".format(inputs["subject"]), inputs),
                           ("outputs_{0}".format(inputs["subject"]), outputs),
                           ("runtime_{0}".format(inputs["subject"]), runtime)]:
    log_file = os.path.join(logdir, "{0}.json".format(name))
    with open(log_file, "wt") as open_file:
        json.dump(final_struct, open_file, sort_keys=True, check_circular=True,
                  indent=4)
if verbose > 1:
    print("[final]")
    pprint(outputs)
